{
  "condition": "consensus",
  "timestamp": "2026-02-18T10:47:14.064976",
  "total": 105,
  "passed": 37,
  "pass_rate": 0.3524,
  "tasks": [
    {
      "task_id": "archeology-easy-10",
      "category": "archeology",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 55.44,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_173116_6957f841",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Singapore",
        "actual_answer": "Singapore",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-easy-11",
      "category": "archeology",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 124.78,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_173211_31969541",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 17.4274,
        "actual_answer": 16.5332,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-easy-3",
      "category": "archeology",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 63.3,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_173416_8a170d8a",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 3.1333,
        "actual_answer": 2.6733,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-easy-4",
      "category": "archeology",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 55.6,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_173532_dd5d7aac",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 207878.8774,
        "actual_answer": 207878.8774,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-easy-6",
      "category": "archeology",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 107.12,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_173627_4bffeb87",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "S\u00e3o Paulo",
        "actual_answer": "S\u00e3o Paulo",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-easy-8",
      "category": "archeology",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 61.74,
      "total_llm_calls": 5,
      "success": true,
      "case_id": "case_20260217_173814_1580668d",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 52,
        "actual_answer": "82",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-hard-1",
      "category": "archeology",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 118.34,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_173929_61633587",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 8577.5298,
        "actual_answer": 7103.132,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-hard-12",
      "category": "archeology",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 89.01,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_174126_b2554049",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 409,
        "actual_answer": "0",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-hard-2",
      "category": "archeology",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 117.44,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_174309_70b2655c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 38.42,
        "actual_answer": 36.02,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-hard-5",
      "category": "archeology",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 217.66,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_174519_df0ee101",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 66158.3691,
        "actual_answer": NaN,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-hard-7",
      "category": "archeology",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 182.21,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_174856_70dd06b9",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 274,
        "actual_answer": "274",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "archeology-hard-9",
      "category": "archeology",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 1186.48,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_175158_22c62c8f",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.015648,
        "actual_answer": -0.232988,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-easy-1",
      "category": "astronomy",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 209.82,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_181145_09f04e2b",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 15,
        "actual_answer": 3.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-easy-2",
      "category": "astronomy",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 625.3,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_181514_f0bb544f",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 7.52,
        "actual_answer": 7.520031923035929,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-easy-3",
      "category": "astronomy",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 376.05,
      "total_llm_calls": 8,
      "success": true,
      "case_id": "case_20260217_182540_876616e2",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 7.95e-13,
        "actual_answer": 8.07216619806026e-13,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-easy-4",
      "category": "astronomy",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 95.22,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_183156_0c47efb4",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "The average period is 11 years, with maxima in 1968, 1979, 1989, 2000, and 2014, and minima in 1964, 1976, 1986, 1996, and 2008.",
        "actual_answer": "Approximate period: 11.5 years. Top 5 maxima years: [1968, 1979, 1989, 2000, 2014]. Top 5 minima years: [1964, 1976, 1986, 1996, 2008].",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-easy-5",
      "category": "astronomy",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 156.9,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_183332_092a1abb",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 2,
        "actual_answer": 15.06433605,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-easy-6",
      "category": "astronomy",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 96.8,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_183609_ca7d3220",
      "output_shape": [
        2,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          0.0193,
          -0.002
        ],
        "actual_answer": [
          0.006852942711761604,
          0.014564171417902972
        ],
        "answer_type": "list_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-hard-10",
      "category": "astronomy",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 466.76,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_183746_fbd03754",
      "output_shape": [
        2,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          "Proton_flux_>30_Mev",
          -0.193
        ],
        "actual_answer": [
          "RMS_BY_GSE_nT",
          "-0.140"
        ],
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-hard-11",
      "category": "astronomy",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 237.88,
      "total_llm_calls": 2,
      "success": true,
      "case_id": "case_20260217_184534_5a77e40e",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 4.638e-13,
        "actual_answer": 1.0444781438913572e-12,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-hard-12",
      "category": "astronomy",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 162.72,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_184932_603ec49f",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 66822738.84,
        "actual_answer": 57863371.14,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-hard-7",
      "category": "astronomy",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 4020.5,
      "total_llm_calls": 2,
      "success": true,
      "case_id": "case_20260217_185216_2f55470b",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 1.211e-13,
        "actual_answer": 1.9226323227623284e-13,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-hard-8",
      "category": "astronomy",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 79.44,
      "total_llm_calls": 2,
      "success": true,
      "case_id": "case_20260217_195917_a4dbb31a",
      "output_shape": [
        2,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          6.1655e-07,
          5.1206e-07
        ],
        "actual_answer": [
          "RMSE_Kp: 11.5868",
          "RMSE_Pdyn: 5.4372"
        ],
        "answer_type": "list_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "astronomy-hard-9",
      "category": "astronomy",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 368.82,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_200036_7bbb878c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 24,
        "actual_answer": "24",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-easy-2",
      "category": "biomedical",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 78.86,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_200646_2bf79e09",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 68.5,
        "actual_answer": 68.5,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-easy-6",
      "category": "biomedical",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 145.71,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_200804_1a7751c2",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "IA",
        "actual_answer": "IA",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-easy-9",
      "category": "biomedical",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 192.33,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_201030_ed249503",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": -0.008003975,
        "actual_answer": -0.00800397537386632,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-hard-1",
      "category": "biomedical",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 300.89,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_201440_a22bd58b",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.4765,
        "actual_answer": 0.2598,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-hard-3",
      "category": "biomedical",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 151.6,
      "total_llm_calls": 5,
      "success": true,
      "case_id": "case_20260217_201942_76158a4f",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 60,
        "actual_answer": "2",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-hard-4",
      "category": "biomedical",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 5180.15,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_202213_99a69d6a",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          "FIGO Grade 2"
        ],
        "actual_answer": "Histological grades extracted for 86 tumor samples",
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-hard-5",
      "category": "biomedical",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 81.33,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_214834_5fc21310",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 2.6563,
        "actual_answer": 2.4241,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-hard-7",
      "category": "biomedical",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 159.87,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_214955_088b94a5",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 16,
        "actual_answer": "443",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "biomedical-hard-8",
      "category": "biomedical",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 466.4,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_215243_a7b64b26",
      "output_shape": [
        4,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          "CDK12",
          "SMARCA4"
        ],
        "actual_answer": [
          "CNV|idx|CNV_idx|10.0501|0.000586",
          "CNV|4q_DEL|CNV_4q_DEL|16.0557|0.004883",
          "CNV|1q_AMP|CNV_1q_AMP|25.8764|0.010503",
          "Mutation|signature_C>G|Mutation_signature_C>G|2.3696|0.021972"
        ],
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-easy-1",
      "category": "environment",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 61.62,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_220029_ba79b827",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 4.796,
        "actual_answer": 4.829,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-easy-2",
      "category": "environment",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 90.07,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_220132_7c850003",
      "output_shape": [
        8,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": [
          2003,
          2011,
          2015,
          2018,
          2020,
          2021,
          2022,
          2023
        ],
        "actual_answer": [
          2003,
          2011,
          2015,
          2018,
          2020,
          2021,
          2022,
          2023
        ],
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-easy-3",
      "category": "environment",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 133.31,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_220302_ff51bcfe",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 268,
        "actual_answer": "2012",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-easy-4",
      "category": "environment",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 167.13,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_220516_13e6b125",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 86,
        "actual_answer": "39",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-easy-5",
      "category": "environment",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 352.28,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_220803_31caf0e9",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Ashburnham",
        "actual_answer": "[]",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-easy-6",
      "category": "environment",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 229.05,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_221357_d3a3f602",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 5.14,
        "actual_answer": 0.04,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-10",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 207.74,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_221746_765a8f91",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.206,
        "actual_answer": 0.069,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-11",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 120.73,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_222114_81cf6543",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.37,
        "actual_answer": 0.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-12",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 106.12,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_222315_e4714a33",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Wollaston Beach",
        "actual_answer": "Wollaston",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-13",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 95.25,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_222502_7ca8d68c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 11,
        "actual_answer": 0.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-14",
      "category": "environment",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 156.84,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_222638_a156b708",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Marine",
        "actual_answer": "Marine",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-15",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 185.73,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_222915_d000f135",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Damon Pond Beach (DCR)",
        "actual_answer": "No data available",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-16",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 141.25,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_223222_05e3071d",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 60,
        "actual_answer": "75",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-17",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 86.57,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_223443_70d59ed3",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 47.37,
        "actual_answer": "25.76",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-18",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 227.83,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_223610_eab1a866",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "True",
        "actual_answer": "False",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-19",
      "category": "environment",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 270.71,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_224001_bbab6e82",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "False",
        "actual_answer": "False",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-20",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 341.24,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_224432_be4f1cee",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          "Bucks Creek",
          "Pleasant Street",
          "Forest Street"
        ],
        "actual_answer": "Kings (DCR) @ Eastern Ave., Tenean (DCR), Kings (DCR) @ Kimball Rd.",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-7",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 260.61,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_225013_2f94be6c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 10.87,
        "actual_answer": 9.72,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-8",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 164.44,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_225433_b6c2fde9",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 54.03,
        "actual_answer": 62.5,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "environment-hard-9",
      "category": "environment",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 245.01,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_225718_49cf9409",
      "output_shape": [
        8,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          "Pleasure Bay Beach",
          "Castle Island Beach",
          "City Point Beach"
        ],
        "actual_answer": [
          "City Point",
          "M Street",
          "Carson",
          "Constitution",
          "Malibu",
          "Tenean",
          "Wollaston",
          "Pleasure Bay and Castle Island"
        ],
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-10",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 50.1,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_171826_e5d7db99",
      "output_shape": [
        6,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": [
          2010,
          2011,
          2012,
          2013,
          2014,
          2019
        ],
        "actual_answer": [
          2010,
          2011,
          2012,
          2013,
          2014,
          2019
        ],
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-11",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 50.08,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_230123_ef9648fe",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "No",
        "actual_answer": "No",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-12",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 59.88,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_230213_d2db13aa",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 3,
        "actual_answer": "3",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-13",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 166.19,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_230313_863dc3cf",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 1097.47,
        "actual_answer": "29",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-19",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 73.23,
      "total_llm_calls": 5,
      "success": true,
      "case_id": "case_20260217_230559_3708f273",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.523,
        "actual_answer": 0.827,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-20",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 56.3,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_230712_0d120a54",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 40,
        "actual_answer": 40.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-21",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 110.82,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_230809_e985701c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 15387,
        "actual_answer": "1202",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-25",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 59.07,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_231000_cd254e8b",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "U.S. Space Force",
        "actual_answer": "Active Duty Service Member",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-26",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "FAILED",
      "duration_seconds": 192.45,
      "total_llm_calls": 5,
      "success": false,
      "case_id": "case_20260217_231100_c840f9df",
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-27",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 46.76,
      "total_llm_calls": 5,
      "success": true,
      "case_id": "case_20260217_231413_2f2044df",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 27,
        "actual_answer": "27",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-3",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 94.8,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_231500_6fb059d0",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 13.1628,
        "actual_answer": 13.1628,
        "answer_type": "numeric_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-4",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 97.95,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_231634_17913d5d",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 2111635,
        "actual_answer": "16855347",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-5",
      "category": "legal",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 51.19,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_231812_0087dbf1",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 5435,
        "actual_answer": "5435",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-easy-9",
      "category": "legal",
      "difficulty": "easy",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 54.83,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260217_231904_7b446149",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 2002,
        "actual_answer": "2020",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-1",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 481.79,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_231958_08399a4d",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 12964.8727,
        "actual_answer": "18",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-1",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 491.62,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_232800_9b32e34d",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 12964.8727,
        "actual_answer": 0.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-14",
      "category": "legal",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 254.36,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260217_233612_59b444ee",
      "output_shape": [
        5,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": [
          "Boston-Cambridge-Newton, MA-NH Metropolitan Statistical Area",
          "Providence-Warwick, RI-MA Metropolitan Statistical Area",
          "Hartford-West Hartford-East Hartford, CT Metropolitan Statistical Area",
          "Bridgeport-Stamford-Danbury, CT Metropolitan Statistical Area",
          "Worcester, MA Metropolitan Statistical Area"
        ],
        "actual_answer": [
          "Boston-Cambridge-Newton, Ma-Nh Metropolitan Statistical Area",
          "Providence-Warwick, Ri-Ma Metropolitan Statistical Area",
          "Hartford-West Hartford-East Hartford, Ct Metropolitan Statistical Area",
          "Bridgeport-Stamford-Danbury, Ct Metropolitan Statistical Area",
          "Worcester, Ma Metropolitan Statistical Area"
        ],
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-15",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 11601.93,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260217_234027_7c65d82a",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 243377,
        "actual_answer": 591769.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-16",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 18075.47,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_025349_80c72b44",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Delaware",
        "actual_answer": "DistrictofColumbia",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-17",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 211.51,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_075504_21c61257",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 32542,
        "actual_answer": "0",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-18",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 161.77,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_075836_9e7f1163",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 91000,
        "actual_answer": "711318000",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-2",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 668.8,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_080118_507bd949",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Miami-Fort Lauderdale-West Palm Beach FL Metropolitan Statistical Area",
        "actual_answer": "Processed 452 metropolitan areas with fraud reports",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-22",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 115.89,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_081227_89aeaa02",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.0555,
        "actual_answer": 2952000000.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-23",
      "category": "legal",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 41.21,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_081423_18f871e5",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "District of Columbia",
        "actual_answer": "District of Columbia",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-24",
      "category": "legal",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 141.02,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_081505_ead4a4a5",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Los Angeles-Long Beach-Anaheim CA Metropolitan Statistical Area",
        "actual_answer": "Los Angeles-Long Beach-Anaheim, CA Metropolitan Statistical Area",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-28",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 115.36,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_081726_d11066ba",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Yes",
        "actual_answer": "No",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-29",
      "category": "legal",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 166.19,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_081921_7aa405eb",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Washington-Arlington-Alexandria, DC-VA-MD-WV Metropolitan Statistical Area",
        "actual_answer": "Washington-Arlington-Alexandria, DC-VA-MD-WV Metropolitan Statistical Area",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-30",
      "category": "legal",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 96.13,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_082208_49ba6d61",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "No",
        "actual_answer": "No",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-6",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 84.06,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_082344_b07ba7ba",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 1.1413,
        "actual_answer": "89684",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-7",
      "category": "legal",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 92.31,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_082508_577ce085",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "Bank Account",
        "actual_answer": "No data for specified years",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "legal-hard-8",
      "category": "legal",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 120.57,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_082640_35da88b2",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "True",
        "actual_answer": "True",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-1",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 49.07,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_082841_6b781e60",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": 7805421,
        "actual_answer": 7805421.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-13",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 5549.95,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_082930_cd1dd91c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Great Basin Area",
        "actual_answer": "Great Basin Area",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-15",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 67.44,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_100200_dc2c8ff5",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "No",
        "actual_answer": "No",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-2",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 122.24,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_100308_948c13f3",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "EACC",
        "actual_answer": "EACC",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-3",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": false,
      "status": "FAILED",
      "duration_seconds": 239.99,
      "total_llm_calls": 3,
      "success": false,
      "case_id": "case_20260218_100510_ef04bada",
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-8",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 52.97,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_100910_bdcb54f2",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Lightning",
        "actual_answer": "Lightning",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-easy-9",
      "category": "wildfire",
      "difficulty": "easy",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 117.36,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_101003_5835c9bf",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 0.9076923076923077,
        "expected_answer": -0.0059,
        "actual_answer": -0.0053,
        "answer_type": "numeric_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-10",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 76.8,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_101201_4b6abd82",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Republican",
        "actual_answer": "Republican",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-11",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 50.14,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_101318_410605f4",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Wyoming",
        "actual_answer": "Wyoming",
        "answer_type": "string_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-12",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 54.02,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_101408_fd758832",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "No",
        "actual_answer": "No",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-14",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 179.47,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_101502_d0a99405",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 0.9027777777777777,
        "expected_answer": 0.65,
        "actual_answer": 0.58,
        "answer_type": "numeric_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-16",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "FAILED",
      "duration_seconds": 257.72,
      "total_llm_calls": 6,
      "success": false,
      "case_id": "case_20260218_101801_aae35530",
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-17",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 186.18,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_102219_6c64741c",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.6306822632444711,
        "expected_answer": 4830.9,
        "actual_answer": "2002",
        "answer_type": "numeric_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-18",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 103.02,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_102526_eea0047a",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": "More aggressive suppression does not help fires end faster but helps fires affect less buildings.",
        "actual_answer": "Duration: coef=8.372, p=0.000, direction=slower. Buildings: coef=3.984, p=0.994, direction=more. Conclusion: No, more aggressive suppression does not show significant benefits for faster fire ending or reduced building impact, controlling for weather.",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-19",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 126.97,
      "total_llm_calls": 6,
      "success": true,
      "case_id": "case_20260218_102710_72e8ec43",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.8582656536547028,
        "expected_answer": 32.76,
        "actual_answer": 27.35,
        "answer_type": "numeric_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-20",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 182.39,
      "total_llm_calls": 5,
      "success": true,
      "case_id": "case_20260218_102917_55eb4fd9",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 0.0465,
        "actual_answer": 10.45,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-21",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 170.75,
      "total_llm_calls": 8,
      "success": true,
      "case_id": "case_20260218_103220_36c3b2d7",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": [
          "California",
          "Washington",
          "Idaho"
        ],
        "actual_answer": "Property value loss metric: not_found",
        "answer_type": "list_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-4",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 178.19,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_103510_d8950e7b",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": 2065.1,
        "actual_answer": 0.0,
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-5",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 201.19,
      "total_llm_calls": 8,
      "success": true,
      "case_id": "case_20260218_103809_6a17f426",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.0,
        "expected_answer": -1039,
        "actual_answer": "9",
        "answer_type": "numeric_exact"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-6",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": false,
      "status": "RUN_OK",
      "duration_seconds": 284.38,
      "total_llm_calls": 7,
      "success": true,
      "case_id": "case_20260218_104130_e67322cc",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": false,
        "score": 0.5,
        "expected_answer": 0.519,
        "actual_answer": 0.0,
        "answer_type": "numeric_approximate"
      },
      "condition": "consensus"
    },
    {
      "task_id": "wildfire-hard-7",
      "category": "wildfire",
      "difficulty": "hard",
      "passed": true,
      "status": "PASSED",
      "duration_seconds": 59.28,
      "total_llm_calls": 3,
      "success": true,
      "case_id": "case_20260218_104614_d3ceadb2",
      "output_shape": [
        1,
        1
      ],
      "evaluation": {
        "passed": true,
        "score": 1.0,
        "expected_answer": "Northwest, 2020",
        "actual_answer": "Northwest, 2020",
        "answer_type": "string_approximate"
      },
      "condition": "consensus"
    }
  ]
}